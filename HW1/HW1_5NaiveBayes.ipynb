{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "216d9e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eadd07",
   "metadata": {},
   "source": [
    "If possible, update your sklearn version to 1.3.2 to reduce variance in the versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7826208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install scikit-learn==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd0a3fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 1.3.2.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e04e4b",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "From the 20Newsgroups dataset we fetch the documents belonging to three categories, which we use as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e6475d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'talk.politics.guns',\n",
    "              'sci.space']\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da785a92",
   "metadata": {},
   "source": [
    "For example, the first document in the training data is the following one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a93d9448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: fcrary@ucsu.Colorado.EDU (Frank Crary)\n",
      "Subject: Re: Riddle me this...\n",
      "Nntp-Posting-Host: ucsu.colorado.edu\n",
      "Organization: University of Colorado, Boulder\n",
      "Distribution: usa\n",
      "Lines: 16\n",
      "\n",
      "In article <1r1lp1INN752@mojo.eng.umd.edu> chuck@eng.umd.edu (Chuck Harris - WA3UQV) writes:\n",
      ">>If so, why was CS often employed against tunnels in Vietnam?\n",
      "\n",
      ">CS \"tear-gas\" was used in Vietnam because it makes you wretch so hard that\n",
      ">your stomach comes out thru your throat.  Well, not quite that bad, but\n",
      ">you can't really do much to defend yourself while you are blowing cookies.\n",
      "\n",
      "I think the is BZ gas, not CS or CN. BZ gas exposure results in projectile\n",
      "vomiting, loss of essentially all muscle control, inability to concentrate\n",
      "or think rationally and fatal reactions in a significant fraction of\n",
      "the population. For that reason its use is limited to military\n",
      "applications.\n",
      "\n",
      "                                                          Frank Crary\n",
      "                                                          CU Boulder\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af6f97",
   "metadata": {},
   "source": [
    "The classes are indicated categorically with indices from zero to two by the target vector. The target names tell us which index belongs to which class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28ceeda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, ..., 1, 2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train.target\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ad3956b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'sci.space', 'talk.politics.guns']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebde71a",
   "metadata": {},
   "source": [
    "We represent the documents in a bag of word format. That is, we create a data matrix ``D`` such that ``D[j,i]=1`` if the j-th document contains the i-th feature (word), and ``D[j,i]=0`` otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "167204f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", min_df=5,token_pattern=\"[^\\W\\d_]+\", binary=True)\n",
    "D = vectorizer.fit_transform(train.data)\n",
    "D_test = vectorizer.transform(test.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9fdf2b",
   "metadata": {},
   "source": [
    "We get the allocation of feature indices to words by the following array, containing the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24b0e1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aario', 'aaron', ..., 'zoology', 'zv', 'Ã¿'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d57b38",
   "metadata": {},
   "source": [
    "For example, the word `naive` has the index 4044."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87ace193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4044])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(vectorizer.get_feature_names_out() == 'naive')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "293733f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2964793082149475, 0.3662754786905497, 0.3372452130945028)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5a\n",
    "# assuming that this is to be done on the training set?\n",
    "y_train_0 = np.array([x for x in y_train if x == 0])\n",
    "y_train_1 = np.array([x for x in y_train if x == 1])\n",
    "y_train_2 = np.array([x for x in y_train if x == 2])\n",
    "\n",
    "p_train_0 = y_train_0.size / y_train.size\n",
    "p_train_1 = y_train_1.size / y_train.size\n",
    "p_train_2 = y_train_2.size / y_train.size\n",
    "\n",
    "p_train_0, p_train_1, p_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3e0fac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.56448951, -6.38530041, -4.91644811])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5b\n",
    "alpha = 1e-5\n",
    "I_0 = np.where(y_train == 0)[0]\n",
    "I_1 = np.where(y_train == 1)[0]\n",
    "I_2 = np.where(y_train == 2)[0]\n",
    "\n",
    "class_counts = {0: 0, 1: 0, 2: 0}\n",
    "\n",
    "for i in range(y_train.size):\n",
    "    if D[i, 4044] == 1:\n",
    "        class_counts[y_train[i]] += 1\n",
    "\n",
    "K = vectorizer.get_feature_names_out().size\n",
    "\n",
    "p_train_0 = (class_counts[0] + alpha) / (I_0.size + alpha * K)\n",
    "p_train_1 = (class_counts[1] + alpha) / (I_1.size + alpha * K)\n",
    "p_train_2 = (class_counts[2] + alpha) / (I_2.size + alpha * K)\n",
    "\n",
    "np.log(np.array([p_train_0, p_train_1, p_train_2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.010415194655432721, 0.0016861618753169954, 0.007325102624431206)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5c\n",
    "# log p(y=c)\n",
    "unique_classes, class_count = np.unique(train.target, return_counts=True)\n",
    "probabilities_per_class = (class_count / train.target.size )\n",
    "log_probabilities_per_class = np.log(probabilities_per_class)\n",
    "# p(xd = xdtest | y = c)\n",
    "counts = {}\n",
    "num_words = vectorizer.get_feature_names_out().size\n",
    "train_size = y_train.size\n",
    "for w in range(num_words):\n",
    "    for i in range(train_size):\n",
    "        counts[w, y_train[i]] = 0\n",
    "for w in range(num_words):\n",
    "    for i in range(train_size):\n",
    "        if D[i,w] == 1:\n",
    "            counts[w, y_train[i]] += 1\n",
    "\n",
    "# Here we have the class count for each word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
