{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# The embedding architecture returns the \n",
    "# output of the penultimate layer\n",
    "class Embed(nn.Module):\n",
    "    def __init__(self,embedding_dim=84):\n",
    "        super(Embed, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(256, 120)\n",
    "        self.fc2   = nn.Linear(120, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        return out     \n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self,embedding_dim, classifier):\n",
    "        super(Net, self).__init__()\n",
    "        self.embed = Embed(embedding_dim=embedding_dim)\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embed(x)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def conf(self,x):\n",
    "        out = self.embed(x)\n",
    "        return F.softmax(self.classifier(out),dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data: the first four MNIST classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "2.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "classes = ('0', '1', '2', '3')\n",
    "c=4\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=trans)\n",
    "\n",
    "# Select only some classes \n",
    "idx = train_data.targets < c\n",
    "train_data.targets = train_data.targets[idx]\n",
    "train_data.data = train_data.data[idx]\n",
    "trainloader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=trans)\n",
    "# Select only some classes \n",
    "idx = testset.targets < c\n",
    "testset.targets = testset.targets[idx]\n",
    "testset.data = testset.data[idx]\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train_epoch(net, criterion, optimizer, trainloader, verbose=False):\n",
    "    train_loss, correct, conf = 0, 0, 0\n",
    "    start_time=time.time()\n",
    "    net.train() \n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # Set the gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        # Do the forward pass\n",
    "        logits = net(inputs)\n",
    "        loss = criterion(logits, targets)\n",
    "        if verbose:\n",
    "            print(\"loss:\",loss.item())\n",
    "        # Do the backward pass\n",
    "        loss.backward()\n",
    "        # Do a gradient descent step\n",
    "        optimizer.step()\n",
    "    \n",
    "        with torch.no_grad(): #Disable gradient tracking and compute some statistics\n",
    "            train_loss += loss.item()\n",
    "            y_probs = F.softmax(logits, dim=1)\n",
    "            confBatch, predicted = y_probs.max(1)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            conf+=confBatch.sum().item()\n",
    "    execution_time = (time.time() - start_time)\n",
    "    n=len(trainloader.dataset)\n",
    "    print('Loss: %.3f | Acc: %.3f%% (%d/%d) | Conf %.2f | time (s): %.2f'% (train_loss/len(trainloader), 100.*correct/n, correct, n, 100*conf/n, execution_time))\n",
    "    return (100.*correct/n, 100*conf/n)\n",
    "  \n",
    "def test_acc(net, criterion, data_loader):\n",
    "    net.eval()\n",
    "    test_loss, correct, conf, total = 0,0,0,0\n",
    "    with torch.no_grad(): # disable gradient tracking\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            logits = net(inputs)\n",
    "            loss = criterion(logits, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            y_probs = F.softmax(logits, dim=1)\n",
    "            confBatch, predicted = y_probs.max(1)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            conf+=confBatch.sum().item()\n",
    "    n=len(data_loader.dataset)\n",
    "    print('Loss: %.3f | Acc: %.3f%% (%d/%d) | Conf %.2f'% (test_loss/max(len(data_loader),1), 100.*correct/n, correct, n, 100*conf/n))\n",
    "    return (100.*correct/n, 100*conf/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model and perform the optimization for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "d=2\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "classifier = nn.Linear(d, c, bias=True)\n",
    "net = Net(embedding_dim=d, classifier=classifier)\n",
    "net = net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "sgd = torch.optim.SGD([{'params': net.parameters()},],\n",
    "                lr=0.5, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Loss: 1.394 | Acc: 25.620% (6342/24754) | Conf 29.11 | time (s): 9.78\n",
      "Loss: 1.390 | Acc: 23.575% (980/4157) | Conf 27.75\n",
      "\n",
      "Epoch: 1\n",
      "Loss: 1.393 | Acc: 25.467% (6304/24754) | Conf 29.44 | time (s): 9.11\n",
      "Loss: 1.392 | Acc: 27.303% (1135/4157) | Conf 29.94\n",
      "\n",
      "Epoch: 2\n",
      "Loss: 1.392 | Acc: 26.137% (6470/24754) | Conf 28.95 | time (s): 10.14\n",
      "Loss: 1.392 | Acc: 23.575% (980/4157) | Conf 28.78\n",
      "\n",
      "Epoch: 3\n",
      "Loss: 1.392 | Acc: 25.507% (6314/24754) | Conf 28.85 | time (s): 7.89\n",
      "Loss: 1.397 | Acc: 24.826% (1032/4157) | Conf 28.88\n",
      "\n",
      "Epoch: 4\n",
      "Loss: 1.390 | Acc: 25.616% (6341/24754) | Conf 28.59 | time (s): 9.47\n",
      "Loss: 1.394 | Acc: 27.303% (1135/4157) | Conf 32.17\n",
      "\n",
      "Epoch: 5\n",
      "Loss: 1.392 | Acc: 25.927% (6418/24754) | Conf 29.26 | time (s): 10.92\n",
      "Loss: 1.391 | Acc: 27.303% (1135/4157) | Conf 31.92\n",
      "\n",
      "Epoch: 6\n",
      "Loss: 1.390 | Acc: 25.818% (6391/24754) | Conf 28.37 | time (s): 8.53\n",
      "Loss: 1.389 | Acc: 23.575% (980/4157) | Conf 27.33\n",
      "\n",
      "Epoch: 7\n",
      "Loss: 1.392 | Acc: 25.551% (6325/24754) | Conf 28.66 | time (s): 8.45\n",
      "Loss: 1.394 | Acc: 23.575% (980/4157) | Conf 28.38\n",
      "\n",
      "Epoch: 8\n",
      "Loss: 1.395 | Acc: 25.394% (6286/24754) | Conf 29.59 | time (s): 9.27\n",
      "Loss: 1.408 | Acc: 27.303% (1135/4157) | Conf 31.04\n",
      "\n",
      "Epoch: 9\n",
      "Loss: 1.392 | Acc: 25.858% (6401/24754) | Conf 29.14 | time (s): 10.32\n",
      "Loss: 1.387 | Acc: 24.826% (1032/4157) | Conf 27.34\n",
      "Saving..\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for epoch in range(10):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    train_epoch(net, criterion, sgd, trainloader)\n",
    "    (acc,conf) = test_acc(net,criterion, testloader)\n",
    "\n",
    "print('Saving..')\n",
    "state = {'net': net.state_dict(),'acc': acc}\n",
    "if not os.path.isdir('checkpoint'):\n",
    "    os.mkdir('checkpoint')\n",
    "torch.save(state, './checkpoint/net.t7')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the latent space representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:\t 24.82559538128458\n"
     ]
    }
   ],
   "source": [
    "# Load the saved net\n",
    "classifier = nn.Linear(d, c,bias=True)\n",
    "net = Net(embedding_dim=d, classifier=classifier)\n",
    "checkpoint = torch.load(\"checkpoint/net.t7\",map_location='cpu')\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "net.eval()\n",
    "print('ACC:\\t',checkpoint['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "def scatter_pictures(inputs, outputs, samples=30):\n",
    "    zoom = 0.7\n",
    "        \n",
    "    for j in range(min(inputs.shape[0],samples)):\n",
    "        image = inputs[j,:,:,:].squeeze()\n",
    "        im = OffsetImage(image, cmap=\"gray\",zoom=zoom)\n",
    "        ab = AnnotationBbox(im, (outputs[j,0], outputs[j,1]), xycoords='data', frameon=False, alpha=0.5)\n",
    "        ax.add_artist(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_conf(conf, show_class_assignment=False, x_max=20, y_max=20, x_min=-1, y_min=-1):\n",
    "    x = np.arange(x_min, x_max, 0.05)\n",
    "    y = np.arange(y_min, y_max, 0.05)\n",
    "\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    X = np.array([xx,yy]).reshape(2,x.shape[0]*y.shape[0]).T\n",
    "    Z = conf(torch.from_numpy(X).float()).t()\n",
    "    Z = Z.reshape(-1,y.shape[0],x.shape[0]).cpu().detach().numpy()\n",
    "    if show_class_assignment:\n",
    "        h = plt.contourf(x,y,Z.argmax(axis=0),cmap='magma')\n",
    "    else:\n",
    "        h = plt.contourf(x,y,Z.max(axis=0),cmap='magma')\n",
    "        plt.clim(0, 1)\n",
    "        cb = plt.colorbar()\n",
    "        cb.set_label('Confidence')\n",
    "    plt.axis('scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Representations of out-of-distribution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "c=10\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "\n",
    "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=trans)\n",
    "trainloader_fashion = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=trans)\n",
    "testloader_fashion = torch.utils.data.DataLoader(testset, batch_size=512, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m outputs \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39membed(inputs)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m      3\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m \u001b[43mplot_conf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_max\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_max\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_min\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_min\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m scatter_pictures(inputs, outputs,samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m, in \u001b[0;36mplot_conf\u001b[1;34m(conf, show_class_assignment, x_max, y_max, x_min, y_min)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_conf\u001b[39m(conf, show_class_assignment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, x_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, y_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, x_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, y_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marange(x_min, x_max, \u001b[38;5;241m0.05\u001b[39m)\n\u001b[0;32m      4\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(y_min, y_max, \u001b[38;5;241m0.05\u001b[39m)\n\u001b[0;32m      6\u001b[0m     xx, yy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(x, y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs, targets = next(iter(testloader_fashion))\n",
    "outputs = net.embed(inputs).detach()\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "plot_conf((lambda x: torch.softmax(net.classifier(x),dim=1)), x_max =max(outputs[:,0])+5, y_max =max(outputs[:,1])+5, x_min =min(outputs[:,0])-3, y_min =min(outputs[:,1])-3)\n",
    "scatter_pictures(inputs, outputs,samples=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
